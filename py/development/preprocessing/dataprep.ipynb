{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Generator, Any\n",
    "import pandas as pd\n",
    "import json\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rich import print as rprint\n",
    "from mbay_nmt.utils import domain as d\n",
    "from mbay_nmt.utils.models import new_object_id\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "uri = os.environ[\"MONGODB_URI\"]\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi(\"1\"))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command(\"ping\")\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [\n",
    "    d.Entry(**entry)\n",
    "    for entry in client.get_database(\"dictionary\").get_collection(\"entries-prod\").find()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry(id=ObjectId('64eca312f6197fd20d762cf5'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), headword='àlmbétɨ̀, àlmétɨ̀', part_of_speech='NI', sound_filename='NewExpSS2215.mp3', french=Translation(translation='match', key='m'), english=Translation(translation='match.', key='m'), related_word=None, grammatical_note=None, examples=[Example(id=ObjectId('64eca312f6197fd20d76096f'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='gà àlmbétɨ̀', english=Translation(translation='-light a match', key='l'), french=Translation(translation='allumer une allumette', key='a'), sound_filename=None), Example(id=ObjectId('64eca312f6197fd20d760970'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='ī-gá àlmbétɨ̀ ādɨ̄-m̄.', english=Translation(translation='Light a match for me.', key='l'), french=Translation(translation='Allumez une allumette pour moi.', key='a'), sound_filename='NBM9_07308.mp3'), Example(id=ObjectId('64eca312f6197fd20d760971'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='kùm-àlmbétɨ̀', english=Translation(translation='-unlit match stick', key='u'), french=Translation(translation='allumette non allumée', key='a'), sound_filename=None), Example(id=ObjectId('64eca312f6197fd20d760972'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='Màn̄ à ɔ̀dɨ̀ kùm-àlmbétɨ̀ ànḛ̄ à ùnjɨ̄ àĺ.', english=Translation(translation=\"If water touches a matchstick it won't light.\", key='i'), french=Translation(translation=\"Si l'eau touche une allumette, elle ne s'allumera pas.\", key='s'), sound_filename='NewExpSS2219.mp3'), Example(id=ObjectId('64eca312f6197fd20d760973'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='kāgɨ̄-àlmbétɨ̀', english=Translation(translation='-used match stick', key='u'), french=Translation(translation='-allumette utilisée', key='a'), sound_filename=None), Example(id=ObjectId('64eca312f6197fd20d760974'), created_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 12, 27, 55, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64eca312f6197fd20d762cf5'), type='entry'), mbay='ādɨ̄-m̄ kāgɨ̄-àlmbétɨ̀ kɨ́rā m̄-ɗāa-ň mbī-ḿ.', english=Translation(translation='Give me a used matchstick so I can clean my ear out with it.', key='g'), french=Translation(translation=\"Donne-moi une allumette utilisée pour que je puisse me nettoyer l'oreille avec.\", key='d'), sound_filename='NewExpSS2225.mp3')], expressions=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict\n",
    "\n",
    "\n",
    "class Record(TypedDict):\n",
    "    type: Literal[\"entry\", \"example\", \"expression\"]\n",
    "    mbay: str\n",
    "    french: str\n",
    "    english: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'entry',\n",
       "  'mbay': 'àlmbétɨ̀, àlmétɨ̀',\n",
       "  'french': 'match',\n",
       "  'english': 'match.'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'gà àlmbétɨ̀',\n",
       "  'french': 'allumer une allumette',\n",
       "  'english': '-light a match'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'ī-gá àlmbétɨ̀ ādɨ̄-m̄.',\n",
       "  'french': 'Allumez une allumette pour moi.',\n",
       "  'english': 'Light a match for me.'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'kùm-àlmbétɨ̀',\n",
       "  'french': 'allumette non allumée',\n",
       "  'english': '-unlit match stick'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'Màn̄ à ɔ̀dɨ̀ kùm-àlmbétɨ̀ ànḛ̄ à ùnjɨ̄ àĺ.',\n",
       "  'french': \"Si l'eau touche une allumette, elle ne s'allumera pas.\",\n",
       "  'english': \"If water touches a matchstick it won't light.\"},\n",
       " {'type': 'example',\n",
       "  'mbay': 'kāgɨ̄-àlmbétɨ̀',\n",
       "  'french': '-allumette utilisée',\n",
       "  'english': '-used match stick'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'ādɨ̄-m̄ kāgɨ̄-àlmbétɨ̀ kɨ́rā m̄-ɗāa-ň mbī-ḿ.',\n",
       "  'french': \"Donne-moi une allumette utilisée pour que je puisse me nettoyer l'oreille avec.\",\n",
       "  'english': 'Give me a used matchstick so I can clean my ear out with it.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]\n",
    "\n",
    "\n",
    "def entry_to_records(entry: d.Entry) -> Generator[Record, Any, None]:\n",
    "    yield {\n",
    "        \"type\": \"entry\",\n",
    "        \"mbay\": entry.headword,\n",
    "        \"french\": entry.french.translation,\n",
    "        \"english\": entry.english.translation,\n",
    "    }\n",
    "\n",
    "    for example in entry.examples:\n",
    "        yield {\n",
    "            \"type\": \"example\",\n",
    "            \"mbay\": example.mbay,\n",
    "            \"french\": example.french.translation,\n",
    "            \"english\": example.english.translation,\n",
    "        }\n",
    "\n",
    "    for expression in entry.expressions:\n",
    "        yield {\n",
    "            \"type\": \"expression\",\n",
    "            \"mbay\": expression.mbay,\n",
    "            \"french\": expression.french.translation,\n",
    "            \"english\": expression.english.translation,\n",
    "        }\n",
    "\n",
    "\n",
    "list(entry_to_records(entries[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'entry',\n",
       "  'mbay': 'àlmbétɨ̀, àlmétɨ̀',\n",
       "  'french': 'match',\n",
       "  'english': 'match.'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'gà àlmbétɨ̀',\n",
       "  'french': 'allumer une allumette',\n",
       "  'english': '-light a match'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'ī-gá àlmbétɨ̀ ādɨ̄-m̄.',\n",
       "  'french': 'Allumez une allumette pour moi.',\n",
       "  'english': 'Light a match for me.'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'kùm-àlmbétɨ̀',\n",
       "  'french': 'allumette non allumée',\n",
       "  'english': '-unlit match stick'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'Màn̄ à ɔ̀dɨ̀ kùm-àlmbétɨ̀ ànḛ̄ à ùnjɨ̄ àĺ.',\n",
       "  'french': \"Si l'eau touche une allumette, elle ne s'allumera pas.\",\n",
       "  'english': \"If water touches a matchstick it won't light.\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records: list[Record] = []\n",
    "for entry in entries:\n",
    "    records.extend(entry_to_records(entry))\n",
    "\n",
    "# Let's check the first few records\n",
    "records[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0945046586803575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records) / len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATASET_PATH = \"../../datasets/mbay-translations-flattened.csv.gzip\"\n",
    "SPLIT_DATASET_PATH = \"../../datasets/mbay-translations/\"\n",
    "TOKENIZED_DATASET_PATH = \"../../datasets/mbay-translations-tokenized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "df.to_csv(CSV_DATASET_PATH, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af120934d2547f0a00f308de6a93e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19bcc5c8458431c8087a92bde9f52c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f988f4db2f45e5b7966476c1524047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dst = Dataset.from_csv(CSV_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = dst.train_test_split(0.2)\n",
    "test_valid = train_test[\"test\"].train_test_split(0.5)\n",
    "\n",
    "train_test_valid_dst = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60737aa38db94063828f6f2281fe51ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bc4a0cfd3f47d0a3f6772c023b77fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64027a961ee84fd998187acdb5b1498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_valid_dst.save_to_disk(SPLIT_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde3aa5f261241f68a52bbaad6cbb5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b64ec63919d4d6594235e6466a3f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0460fd2bd754d2fb3c1c41f8432b126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "Lang = Literal[\"mbay\", \"french\", \"english\"]\n",
    "\n",
    "prefix = \"Translate English to Mbay: \"\n",
    "source_lang: Lang = \"english\"\n",
    "target_lang: Lang = \"mbay\"\n",
    "\n",
    "\n",
    "def prepare_pair(examples, prefix: str, source_lang: Lang, target_lang: Lang):\n",
    "    inputs = [prefix + example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def preprocess_records(examples):\n",
    "    inputs: list[str] = []\n",
    "    targets: list[str] = []\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate English to Mbay: \", \"english\", \"mbay\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate Mbay to English: \", \"mbay\", \"english\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate French to Mbay: \", \"french\", \"mbay\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate Mbay to French: \", \"mbay\", \"french\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=128, truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbay_nmt.fine_tune_t5.utils import preprocess_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/t5-v1_1-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type', 'mbay', 'french', 'english']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dst.column_names[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338a76c7796a4fc88313f434973284c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749a7faf8fe24880bcfd4f80eb2e7bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bb7dfff5b24a99800b0c76b467bceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "final_dst = train_test_valid_dst.map(\n",
    "    partial(preprocess_records, t5_tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_test_valid_dst[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2fd614b87e409f93639a102598339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/35248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121185a134a6471f93a9d422409b7a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e876ca50154024956caa1c3c2f68ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_dst.save_to_disk(TOKENIZED_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
