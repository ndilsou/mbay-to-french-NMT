{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Generator, Any\n",
    "import pandas as pd\n",
    "import json\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rich import print as rprint\n",
    "# from mbay_dict.core import domain as d\n",
    "# from mbay_dict.core.models import new_object_id\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "uri = os.environ[\"MONGODB_URI\"]\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi(\"1\"))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command(\"ping\")\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [\n",
    "    d.Entry(**entry)\n",
    "    for entry in client.get_database(\"dictionary\").get_collection(\"entries-prod\").find()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry(id=ObjectId('64fc50f7286b18ef7de0db22'), created_at=datetime.datetime(2023, 9, 9, 11, 3, 19, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 11, 3, 19, tzinfo=TzInfo(UTC)), headword='màn̄-kò̰o̰', part_of_speech='NI', sound_filename='Tape13MbayBB232.mp3', french=Translation(translation='inondation', key='i'), english=Translation(translation='flooding', key='f'), related_word=None, grammatical_note=None, examples=[Example(id=ObjectId('64fc50f7286b18ef7de0db23'), created_at=datetime.datetime(2023, 9, 9, 11, 3, 19, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2023, 9, 9, 11, 3, 19, tzinfo=TzInfo(UTC)), parent_id=ParentId(id=ObjectId('64fc50f7286b18ef7de0db22'), type='entry'), mbay='Dà-nā̰a̰ màn̄-kò̰o̰ tɨ́', english=Translation(translation='during the season of flooding', key='d'), french=Translation(translation='pendant la saison des inondations', key='p'), sound_filename='Tape13MbayBB234.mp3')], expressions=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict\n",
    "\n",
    "\n",
    "class Record(TypedDict):\n",
    "    type: Literal[\"entry\", \"example\", \"expression\"]\n",
    "    mbay: str\n",
    "    french: str\n",
    "    english: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'entry',\n",
       "  'mbay': 'màn̄-kò̰o̰',\n",
       "  'french': 'inondation',\n",
       "  'english': 'flooding'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'Dà-nā̰a̰ màn̄-kò̰o̰ tɨ́',\n",
       "  'french': 'pendant la saison des inondations',\n",
       "  'english': 'during the season of flooding'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]\n",
    "\n",
    "\n",
    "def entry_to_records(entry: d.Entry) -> Generator[Record, Any, None]:\n",
    "    yield {\n",
    "        \"type\": \"entry\",\n",
    "        \"mbay\": entry.headword,\n",
    "        \"french\": entry.french.translation,\n",
    "        \"english\": entry.english.translation,\n",
    "    }\n",
    "\n",
    "    for example in entry.examples:\n",
    "        yield {\n",
    "            \"type\": \"example\",\n",
    "            \"mbay\": example.mbay,\n",
    "            \"french\": example.french.translation,\n",
    "            \"english\": example.english.translation,\n",
    "        }\n",
    "\n",
    "    for expression in entry.expressions:\n",
    "        yield {\n",
    "            \"type\": \"expression\",\n",
    "            \"mbay\": expression.mbay,\n",
    "            \"french\": expression.french.translation,\n",
    "            \"english\": expression.english.translation,\n",
    "        }\n",
    "\n",
    "\n",
    "list(entry_to_records(entries[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'entry',\n",
       "  'mbay': 'màn̄-kò̰o̰',\n",
       "  'french': 'inondation',\n",
       "  'english': 'flooding'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'Dà-nā̰a̰ màn̄-kò̰o̰ tɨ́',\n",
       "  'french': 'pendant la saison des inondations',\n",
       "  'english': 'during the season of flooding'},\n",
       " {'type': 'entry',\n",
       "  'mbay': 'màkɨ̀m',\n",
       "  'french': \"grands [d'activité]\",\n",
       "  'english': 'great ones [of activity]'},\n",
       " {'type': 'example',\n",
       "  'mbay': 'ɓōo tɨ́ dá màkɨ̀m yá̰a̰-kɨ́-sà-gɨ̄ à òy-n̄ ngá̰y.',\n",
       "  'french': 'Pendant les périodes de famine, les grands mangeurs meurent comme des mouches.',\n",
       "  'english': 'During periods of famine, the great eaters die like flies.'},\n",
       " {'type': 'expression',\n",
       "  'mbay': 'màkɨ̀m dèē',\n",
       "  'french': 'un grand mangeur',\n",
       "  'english': 'a great eater'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records: list[Record] = []\n",
    "for entry in entries:\n",
    "    records.extend(entry_to_records(entry))\n",
    "\n",
    "# Let's check the first few records\n",
    "records[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0945046586803575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records) / len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceadf94a28f4617a3e748658daca970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38921c07e70147198988111f7cacfd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a9d16e6fcd418a913d48c9ee2d3904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dst = Dataset.from_csv(\"records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde3aa5f261241f68a52bbaad6cbb5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b64ec63919d4d6594235e6466a3f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0460fd2bd754d2fb3c1c41f8432b126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[794, 1]], 'attention_mask': [[1, 1]], 'labels': [[2275, 210, 1]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"test\"], text_target=[\"wow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "Lang = Literal[\"mbay\", \"french\", \"english\"]\n",
    "\n",
    "prefix = \"Translate English to Mbay: \"\n",
    "source_lang: Lang = \"english\"\n",
    "target_lang: Lang = \"mbay\"\n",
    "\n",
    "\n",
    "def prepare_pair(examples, prefix: str, source_lang: Lang, target_lang: Lang):\n",
    "    inputs = [prefix + example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def preprocess_records(examples):\n",
    "    inputs: list[str] = []\n",
    "    targets: list[str] = []\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate English to Mbay: \", \"english\", \"mbay\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate Mbay to English: \", \"mbay\", \"english\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate French to Mbay: \", \"french\", \"mbay\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    _inputs, _target = prepare_pair(\n",
    "        examples, \"Translate Mbay to French: \", \"mbay\", \"french\"\n",
    "    )\n",
    "    inputs.extend(_inputs)\n",
    "    targets.extend(_target)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=128, truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df64e5758e8948c9a0cb738995c6dedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_translations = dst.map(\n",
    "    preprocess_records, batched=True, remove_columns=dst.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 44060\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
