{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/nasoungadoy/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(profile_name=\"ai-sandbox-sso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserId': 'AROAX4Q5STILGJLLHY6I6:nasoungadoy',\n",
       " 'Account': '542301657622',\n",
       " 'Arn': 'arn:aws:sts::542301657622:assumed-role/AWSReservedSSO_AdministratorAccess_bfd3f71331b64628/nasoungadoy',\n",
       " 'ResponseMetadata': {'RequestId': '30bb6935-f388-4478-bca3-edaa2e5f2868',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '30bb6935-f388-4478-bca3-edaa2e5f2868',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '480',\n",
       "   'date': 'Wed, 25 Oct 2023 22:54:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client(\"sts\").get_caller_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = os.environ[\"SAGEMAKER_ROLE_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/nasoungadoy/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/nasoungadoy/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::542301657622:role/service-role/AmazonSageMaker-ExecutionRole-20231002T234337\n",
      "sagemaker bucket: sagemaker-us-east-1-542301657622\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# try:\n",
    "#     role = sagemaker.get_execution_role()\n",
    "# except ValueError:\n",
    "iam = boto3.client(\"iam\")\n",
    "role = iam.get_role(RoleName=role_name)[\"Role\"][\"Arn\"]\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZED_DATASET_PATH = \"../../datasets/mbay-translations-tokenized\"\n",
    "dataset = load_from_disk(TOKENIZED_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_s3_path = f\"s3://{sess.default_bucket()}/processed/mbay/mt5/\"\n",
    "sample_dataset_s3_path = f\"s3://{sess.default_bucket()}/processed/mbay-samples/mt5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for perso-sso\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058a383736324d998000c3950ad337c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/34320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3708f6798e874e18be44bfc9a47687b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066cb3ffd7e6491190a9e40fad940327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset to: s3://sagemaker-us-east-1-542301657622/processed/mbay/mt5/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f38bd148c047ef976421b0de8b191b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/34320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8985f410a348e7b69b8a07fe21d5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251d448f85044d07ae5d876c88d08728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e1529c297433bb444e0fffa6c1c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10c87e05dc34dfeaaa443d29b1f2a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b28019105e042f3bf09631ddfd1ad98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample dataset to: s3://sagemaker-us-east-1-542301657622/processed/mbay-samples/mt5/\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "# Load dataset from disk and upload to S3\n",
    "dataset.save_to_disk(input_dataset_s3_path)\n",
    "print(f\"training dataset to: {input_dataset_s3_path}\")\n",
    "\n",
    "sampled_dataset = dataset.shuffle().filter(lambda x, i: i < 500, with_indices=True)\n",
    "sampled_dataset.save_to_disk(sample_dataset_s3_path)\n",
    "print(f\"sample dataset to: {sample_dataset_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mbay-nmt-google-mt5-small'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from mbay_nmt.training.core import training_job_name\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "use_spot_instances = True\n",
    "model_id = \"google/mt5-small\"\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = training_job_name(model_id)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = os.environ[\"WANDB_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/nasoungadoy/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,  # pre-trained model\n",
    "    \"dataset_path\": \"/opt/ml/input/data/training\",  # path where sagemaker will save training dataset\n",
    "    \"epochs\": 10,  # number of training epochs\n",
    "    \"per_device_train_batch_size\": 8,  # batch size for training\n",
    "    \"lr\": 2e-4,  # learning rate used during training\n",
    "    \"hf_token\": HfFolder.get_token(),  # huggingface token to access llama 2\n",
    "    \"wandb_token\": WANDB_TOKEN,\n",
    "    \"merge_weights\": True,  # wether to merge LoRA into the model (needs more memory) // we only have access to g5.2xlarge. This is not enough memory\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,  # pre-trained model\n",
    "    \"dataset_path\": \"/opt/ml/input/data/training\",  # path where sagemaker will save training dataset\n",
    "    \"epochs\": 1,  # number of training epochs\n",
    "    \"per_device_train_batch_size\": 8,  # batch size for training\n",
    "    \"lr\": 2e-4,  # learning rate used during training\n",
    "    \"hf_token\": HfFolder.get_token(),  # huggingface token to access llama 2\n",
    "    \"wandb_token\": WANDB_TOKEN,\n",
    "    \"merge_weights\": True,  # wether to merge LoRA into the model (needs more memory) // we only have access to g5.2xlarge. This is not enough memory\n",
    "}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"run.py\",  # train script\n",
    "    source_dir=\"../../projects/run_fine_tune_t5\",  # directory which includes all the files needed for training\n",
    "    instance_type=\"ml.g5.2xlarge\",  # instances type used for the training job\n",
    "    instance_count=1,  # the number of instances used for training\n",
    "    base_job_name=job_name,  # the name of the training job\n",
    "    role=role,  # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size=200,  # the size of the EBS volume in GB\n",
    "    # max_run=2 * 24 * 60 * 60,\n",
    "    transformers_version=\"4.28\",  # the transformers version used in the training job\n",
    "    pytorch_version=\"2.0\",  # the pytorch_version version used in the training job\n",
    "    py_version=\"py310\",  # the python version used in the training job\n",
    "    hyperparameters=hyperparameters,  # the hyperparameters passed to the training job\n",
    "    # use_spot_instances   =  use_spot_instances, # wether to use spot instances or not\n",
    "    environment={\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\"\n",
    "    },  # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: mbay-nmt-google-mt5-small-2023-10-25-22-55-16-566\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "# data = {\"training\": training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(sample_dataset_s3_path, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
